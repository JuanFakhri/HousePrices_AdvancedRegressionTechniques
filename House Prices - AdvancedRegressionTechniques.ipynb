{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition Description\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "# DecisionTree Regressor of Housing Price Competition\n",
    "Link to competition: \\ submitted by: Juan Fakri\n",
    "\n",
    "This code example uses sklearn Linear_model to predict the price of a house based on some characteristics of the house.\n",
    "\n",
    "Here are some strategies to solve the problem:\n",
    "\n",
    "1. Import library and get data\n",
    "2. clean up data\n",
    "3. Build, fit, and evaluate Sklearn linear regression models that perform predictions.\n",
    "4. Run hyperparameter tuning\n",
    "5. submit your work \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.   Import the Libraries and get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Juan Pablo Contreras\n",
    "# This is the notebook used for my submission for the House Prices - Advanced Regression Techniques competition\n",
    "\n",
    "import math\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "NaN values ​​in the dataset:\n",
    "Yes| Categorical values ​​in the dataset:\n",
    "Yes| Numbers in dataset:\n",
    "Yes The only difference between the training dataset and the test dataset is that the test dataset does not contain the SalePrice column. To clear the data, do the following: \n",
    "\n",
    "- 2.1. The SalePrice column is removed from the training dataset to match the columns of the training and test DFs. \n",
    "- 2.2. The test DF is added to the training DF, so we can perform cleanup on both the training DF and the test DF.\n",
    "- 2.3. Categorical values ​​are hot encoded using pands get_dummies() function \n",
    "- 2.4. NaN values ​​are converted to -1.\n",
    "- 2.5. The dataset is again split into training and testing.\n",
    "- 2.6. The training dataset is split into two parts (training and validation) to see how well the trained model performs. \n",
    "- 2.7. Data are normalized using the training data. Validation and test data are transformed using fitting parameters for normalization of training data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Delete SalePrice from Training Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows in training data: 1460\n",
      "num rows in test data: 1459\n"
     ]
    }
   ],
   "source": [
    "# find number of rows\n",
    "num_rows_train = len(train_data.index)\n",
    "print(\"num rows in training data: \" + str(num_rows_train))\n",
    "print(\"num rows in test data: \" + str(len(test_data.index)))\n",
    "\n",
    "# store and drop the training predictions\n",
    "y_train = train_data.iloc[:,-1]\n",
    "train_data.drop(columns=train_data.columns[-1], \n",
    "        axis=1, \n",
    "        inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows in all data: 2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_17184\\479556246.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = train_data.append(test_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# merge all data for cleaning\n",
    "all_data = train_data.append(test_data, ignore_index=True)\n",
    "print(\"num rows in all data: \" + str(len(all_data.index)))\n",
    "\n",
    "# delete id column because ID is not a predictor of house price\n",
    "ids = all_data.drop('Id', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 & 2.4 Handle Categorical and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  SaleType_New  \\\n",
       "0          2003       196.0       706.0  ...               0             0   \n",
       "1          1976         0.0       978.0  ...               0             0   \n",
       "2          2002       162.0       486.0  ...               0             0   \n",
       "3          1970         0.0       216.0  ...               0             0   \n",
       "4          2000       350.0       655.0  ...               0             0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0             0            1                      0                      0   \n",
       "1             0            1                      0                      0   \n",
       "2             0            1                      0                      0   \n",
       "3             0            1                      1                      0   \n",
       "4             0            1                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 289 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical data to numerical (0 or 1)\n",
    "all_data = pd.get_dummies(data=all_data)\n",
    "\n",
    "# replace NaN values\n",
    "all_data = all_data.fillna(-1)\n",
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  SaleType_New  \\\n",
       "0          2003       196.0       706.0  ...               0             0   \n",
       "1          1976         0.0       978.0  ...               0             0   \n",
       "2          2002       162.0       486.0  ...               0             0   \n",
       "3          1970         0.0       216.0  ...               0             0   \n",
       "4          2000       350.0       655.0  ...               0             0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0             0            1                      0                      0   \n",
       "1             0            1                      0                      0   \n",
       "2             0            1                      0                      0   \n",
       "3             0            1                      1                      0   \n",
       "4             0            1                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 289 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "       ...\n",
       "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
       "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
       "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
       "       'SaleCondition_Partial'],\n",
       "      dtype='object', length=289)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with missing values: 0\n",
      "No data is lost!!!\n"
     ]
    }
   ],
   "source": [
    "def missing_value_describe(data):\n",
    "# Check for missing values in data\n",
    "    missing_value_stats = (data.isnull().sum() / len(data)*100)\n",
    "    missing_value_col_count = sum(missing_value_stats > 0)\n",
    "    missing_value_stats = missing_value_stats.sort_values(ascending=False)[:missing_value_col_count]\n",
    "    print(\"Number of columns with missing values:\", missing_value_col_count)\n",
    "    if missing_value_col_count != 0:\n",
    "# Print column names with percentage of missing values\n",
    "        print(\"\\nPercentage lost (decreasing):\")\n",
    "        print(missing_value_stats)\n",
    "    else:\n",
    "        print(\"No data is lost!!!\")\n",
    "missing_value_describe(all_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Split data back into Train, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows in X train: 1460\n",
      "num rows in y train: 1460\n",
      "num rows in X test: 1459\n",
      "Training data features head: \n",
      "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "0   1          60         65.0     8450            7            5       2003   \n",
      "1   2          20         80.0     9600            6            8       1976   \n",
      "2   3          60         68.0    11250            7            5       2001   \n",
      "3   4          70         60.0     9550            7            5       1915   \n",
      "4   5          60         84.0    14260            8            5       2000   \n",
      "\n",
      "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  SaleType_New  \\\n",
      "0          2003       196.0       706.0  ...               0             0   \n",
      "1          1976         0.0       978.0  ...               0             0   \n",
      "2          2002       162.0       486.0  ...               0             0   \n",
      "3          1970         0.0       216.0  ...               0             0   \n",
      "4          2000       350.0       655.0  ...               0             0   \n",
      "\n",
      "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
      "0             0            1                      0                      0   \n",
      "1             0            1                      0                      0   \n",
      "2             0            1                      0                      0   \n",
      "3             0            1                      1                      0   \n",
      "4             0            1                      0                      0   \n",
      "\n",
      "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
      "0                     0                     0                     1   \n",
      "1                     0                     0                     1   \n",
      "2                     0                     0                     1   \n",
      "3                     0                     0                     0   \n",
      "4                     0                     0                     1   \n",
      "\n",
      "   SaleCondition_Partial  \n",
      "0                      0  \n",
      "1                      0  \n",
      "2                      0  \n",
      "3                      0  \n",
      "4                      0  \n",
      "\n",
      "[5 rows x 289 columns]\n",
      "\n",
      "Training data predictions head: \n",
      "0    208500\n",
      "1    181500\n",
      "2    223500\n",
      "3    140000\n",
      "4    250000\n",
      "Name: SalePrice, dtype: int64\n",
      "\n",
      "Test data features head:\n",
      "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
      "1460  1461          20         80.0    11622            5            6   \n",
      "1461  1462          20         81.0    14267            6            6   \n",
      "1462  1463          60         74.0    13830            5            5   \n",
      "1463  1464          60         78.0     9978            6            6   \n",
      "1464  1465         120         43.0     5005            8            5   \n",
      "\n",
      "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n",
      "1460       1961          1961         0.0       468.0  ...               0   \n",
      "1461       1958          1958       108.0       923.0  ...               0   \n",
      "1462       1997          1998         0.0       791.0  ...               0   \n",
      "1463       1998          1998        20.0       602.0  ...               0   \n",
      "1464       1992          1992         0.0       263.0  ...               0   \n",
      "\n",
      "      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
      "1460             0             0            1                      0   \n",
      "1461             0             0            1                      0   \n",
      "1462             0             0            1                      0   \n",
      "1463             0             0            1                      0   \n",
      "1464             0             0            1                      0   \n",
      "\n",
      "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
      "1460                      0                     0                     0   \n",
      "1461                      0                     0                     0   \n",
      "1462                      0                     0                     0   \n",
      "1463                      0                     0                     0   \n",
      "1464                      0                     0                     0   \n",
      "\n",
      "      SaleCondition_Normal  SaleCondition_Partial  \n",
      "1460                     1                      0  \n",
      "1461                     1                      0  \n",
      "1462                     1                      0  \n",
      "1463                     1                      0  \n",
      "1464                     1                      0  \n",
      "\n",
      "[5 rows x 289 columns]\n"
     ]
    }
   ],
   "source": [
    "# split data back into train and test data\n",
    "X_train = all_data.iloc[0:num_rows_train,:]\n",
    "print(\"num rows in X train: \" + str(len(X_train.index)))\n",
    "print(\"num rows in y train: \" + str(len(y_train.index)))\n",
    "X_test = all_data.iloc[num_rows_train:,:]\n",
    "print(\"num rows in X test: \" + str(len(X_test.index)))\n",
    "\n",
    "print(\"Training data features head: \")\n",
    "print(X_train.head())\n",
    "print()\n",
    "print(\"Training data predictions head: \")\n",
    "print(y_train.head())\n",
    "print()\n",
    "print(\"Test data features head:\")\n",
    "print(X_test.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Split train data into train and validation\n",
    "The new training data will be 80% of the train dataset, and the validation data 20% of the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_val_transf = scaler.transform(X_val)\n",
    "X_test_transf = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build, fit, and evaluate linear regression models\n",
    "A sklearn linear regression model is used.\n",
    "\n",
    "1. The model is built using the sklearn library\n",
    "2. The model is fitted using the training data\n",
    "3. The model is validated against validation data\n",
    "4. Predictions are made based on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear model\n",
    "regr = linear_model.LinearRegression()\n",
    "# fit model using training data\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluating the Model\n",
    "\n",
    "<b>How good did the model fit the training data?</b>\n",
    "\n",
    "First, find the R^2 value of the training data predictions to see how well the linear model fits the trained data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training data: 0.9401454003464302\n"
     ]
    }
   ],
   "source": [
    "r2_train = regr.score(X_train,y_train)\n",
    "print(\"R^2 on training data: \" + str(r2_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model fit is very good, reaching a maximum value of R^2 which is 1.  Saying that the linear model fits the training data perfectly. Let's hope this model works well on untrained data!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How good is the model on new data?</b>\n",
    "\n",
    "Now that you know how your model behaves on training data, you want to know how it behaves on data you've never seen before. Use the score() function to make predictions on validation data and evaluate how good those predictions are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on validation data: 0.44377267188435565\n"
     ]
    }
   ],
   "source": [
    "r2_validation = regr.score(X_val,y_val)\n",
    "print(\"R^2 on validation data: \" + str(r2_validation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of R^2 in the validation dataset is about 0.443, not good for my heart's feelings... Let's see we'll predict the sale price of a home in a validation data set and then see how far this prediction is from the actual sale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five first predictions: \n",
      "[160536.64307101 343707.37847009  89843.95120924 177402.14668826\n",
      " 320387.72170794]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict prices on the validation data\n",
    "pred_val = regr.predict(X_val)\n",
    "print(\"Five first predictions: \")\n",
    "print(pred_val[:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error:\n",
      "\n",
      "65318.030068267515\n"
     ]
    }
   ],
   "source": [
    "# Compare the Predicted values on the validation data set to the actual SalePrices of the validation data set using the root mean squared error\n",
    "MSE = np.square(np.subtract(y_val,pred_val)).mean()   \n",
    "   \n",
    "rsme = math.sqrt(MSE)  \n",
    "print(\"Root Mean Square Error:\\n\")  \n",
    "print(rsme)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This roughly means that on average, the predicted home sale price drops by $65,318 This mistake is huge! This prediction will probably never be used in the real world. Therefore, we need to do some hyper parameter tuning to make the model better at predicting house prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter tuning\n",
    "In this section, we perform some hyperparameter tuning to improve the model's house price predictions. Here's what I do:\n",
    "\n",
    "\n",
    "* 4.1 What is the problem? \n",
    "* 4.2 Solving overfitting using PCA \n",
    "* 4.3 Retraining the model \n",
    "* 4.4 Evaluating a new model \n",
    "\n",
    "<b>What's the problem?</b>\n",
    "\n",
    "This model matches the training data well (R^2 = 1.0). The problem is that this model is very poor at making predictions based on new data (R^2 = 0,77) and therefore does not generalize well. It fits the training data well, but fits the new data poorly, so the model might be too good for the training data. This means that the model uses features that are very important in predicting house prices in the training set, but features that are generally less important in determining house prices. \n",
    "\n",
    "\n",
    "<b>Use PCA to combat overfitting</b>\n",
    "\n",
    "The best way to deal with overfitting in a linear regression model is to not train the model on data whose patterns are purely random. For this, we use the technique of principal component analysis (PCA). PCA can be used to reduce the number of functions used for prediction. \n",
    "\n",
    "Features (columns) can be interdependent, so PCA features are blended into independent components. That way, you have enough components to explain most of the variance in your training data, but you can't have too many components to prevent unique patterns in your training data from being learned.\n",
    "\n",
    "Try the percentage of variance explained by the components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "# Create the PCA models\n",
    "pca_1 = PCA(1)      # use only 1 component\n",
    "pca_3 = PCA(3)      # use only 3 components\n",
    "pca_5 = PCA(5)      # use only 5 components\n",
    "pca_6 = PCA(6)      # use only 5 components\n",
    "pca_7 = PCA(7)      # use only 5 components\n",
    "pca_8 = PCA(8)      # use only 8 components\n",
    "pca_10 = PCA(10)    # use only 10 components\n",
    "\n",
    "# fit the PCA models\n",
    "pca_1.fit(X_train)\n",
    "pca_3.fit(X_train)\n",
    "pca_5.fit(X_train)\n",
    "pca_6.fit(X_train)\n",
    "pca_7.fit(X_train)\n",
    "pca_8.fit(X_train)\n",
    "pca_10.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data using the PCA models\n",
    "\n",
    "# using 1 component\n",
    "pca_1_train_img = pca_1.transform(X_train)\n",
    "pca_1_val_img = pca_1.transform(X_val)\n",
    "\n",
    "# using 3 components\n",
    "pca_3_train_img = pca_3.transform(X_train)\n",
    "pca_3_val_img = pca_3.transform(X_val)\n",
    "\n",
    "# using 5 components\n",
    "pca_5_train_img = pca_5.transform(X_train)\n",
    "pca_5_val_img = pca_5.transform(X_val)\n",
    "\n",
    "# using 6 components\n",
    "pca_6_train_img = pca_6.transform(X_train)\n",
    "pca_6_val_img = pca_6.transform(X_val)\n",
    "\n",
    "# using 7 components\n",
    "pca_7_train_img = pca_7.transform(X_train)\n",
    "pca_7_val_img = pca_7.transform(X_val)\n",
    "\n",
    "# using 8 components\n",
    "pca_8_train_img = pca_8.transform(X_train)\n",
    "pca_8_val_img = pca_8.transform(X_val)\n",
    "\n",
    "# using 10 components\n",
    "pca_10_train_img = pca_10.transform(X_train)\n",
    "pca_10_val_img = pca_10.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the new Linear Regression Models to fit the transformed data\n",
    "\n",
    "# using 1 component\n",
    "regr_1 = linear_model.LinearRegression()\n",
    "regr_1.fit(pca_1_train_img, y_train)\n",
    "\n",
    "# using 3 components\n",
    "regr_3 = linear_model.LinearRegression()\n",
    "regr_3.fit(pca_3_train_img, y_train)\n",
    "\n",
    "# using 5 components\n",
    "regr_5 = linear_model.LinearRegression()\n",
    "regr_5.fit(pca_5_train_img, y_train)\n",
    "\n",
    "# using 5 components\n",
    "regr_6 = linear_model.LinearRegression()\n",
    "regr_6.fit(pca_6_train_img, y_train)\n",
    "\n",
    "# using 5 components\n",
    "regr_5 = linear_model.LinearRegression()\n",
    "regr_5.fit(pca_5_train_img, y_train)\n",
    "\n",
    "# using 5 components\n",
    "regr_7 = linear_model.LinearRegression()\n",
    "regr_7.fit(pca_7_train_img, y_train)\n",
    "\n",
    "# using 8 components\n",
    "regr_8 = linear_model.LinearRegression()\n",
    "regr_8.fit(pca_8_train_img, y_train)\n",
    "\n",
    "# using 10 components\n",
    "regr_10 = linear_model.LinearRegression()\n",
    "regr_10.fit(pca_10_train_img, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of fit on training data for 1 component: 0.07143060084311081\n",
      "R^2 of fit on validation data for 1 component: 0.06350840667036806\n",
      "\n",
      "R^2 of fit on training data for 3 components 0.6075148468250726\n",
      "R^2 of fit on validation data for 3 components 0.7026626008715731\n",
      "\n",
      "R^2 of fit on training data for 5 components 0.6205204707232319\n",
      "R^2 of fit on validation data for 5 components 0.7236616660606632\n",
      "\n",
      "R^2 of fit on training data for 5 components 0.6206670153574783\n",
      "R^2 of fit on validation data for 5 components 0.7244516662858383\n",
      "\n",
      "R^2 of fit on training data for 5 components 0.6217540090610203\n",
      "R^2 of fit on validation data for 5 components 0.7250567593127974\n",
      "\n",
      "R^2 of fit on training data for 8 components 0.6239504191395515\n",
      "R^2 of fit on validation data for 8 components 0.7275278479880866\n",
      "\n",
      "R^2 of fit on training data for 10 components 0.6512775995792758\n",
      "R^2 of fit on validation data for 10 components 0.7516055295817703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find How good the new Models are\n",
    "\n",
    "# using 1 component\n",
    "r2 = regr_1.score(pca_1_train_img, y_train)\n",
    "print(\"R^2 of fit on training data for 1 component: \" + str(r2))\n",
    "r2 = regr_1.score(pca_1_val_img, y_val)\n",
    "print(\"R^2 of fit on validation data for 1 component: \" + str(r2))\n",
    "print()\n",
    "\n",
    "# using 3 components\n",
    "r2 = regr_3.score(pca_3_train_img, y_train)\n",
    "print(\"R^2 of fit on training data for 3 components \" + str(r2))\n",
    "r2 = regr_3.score(pca_3_val_img, y_val)\n",
    "print(\"R^2 of fit on validation data for 3 components \" + str(r2))\n",
    "print()\n",
    "\n",
    "# using 5 components\n",
    "r2 = regr_5.score(pca_5_train_img, y_train)\n",
    "print(\"R^2 of fit on training data for 5 components \" + str(r2))\n",
    "r2 = regr_5.score(pca_5_val_img, y_val)\n",
    "print(\"R^2 of fit on validation data for 5 components \" + str(r2))\n",
    "print()\n",
    "\n",
    "# using 6 components\n",
    "r2 = regr_6.score(pca_6_train_img, y_train)\n",
    "print(\"R^2 of fit on training data for 5 components \" + str(r2))\n",
    "r2 = regr_6.score(pca_6_val_img, y_val)\n",
    "print(\"R^2 of fit on validation data for 5 components \" + str(r2))\n",
    "print()\n",
    "\n",
    "# using 5 components\n",
    "r2 = regr_7.score(pca_7_train_img, y_train)\n",
    "print(\"R^2 of fit on training data for 5 components \" + str(r2))\n",
    "r2 = regr_7.score(pca_7_val_img, y_val)\n",
    "print(\"R^2 of fit on validation data for 5 components \" + str(r2))\n",
    "print()\n",
    "\n",
    "# using 8 components\n",
    "r2 = regr_8.score(pca_8_train_img, y_train)\n",
    "print(\"R^2 of fit on training data for 8 components \" + str(r2))\n",
    "r2 = regr_8.score(pca_8_val_img, y_val)\n",
    "print(\"R^2 of fit on validation data for 8 components \" + str(r2))\n",
    "print()\n",
    "\n",
    "# using 3 components\n",
    "r2 = regr_10.score(pca_10_train_img, y_train)\n",
    "print(\"R^2 of fit on training data for 10 components \" + str(r2))\n",
    "r2 = regr_10.score(pca_10_val_img, y_val)\n",
    "print(\"R^2 of fit on validation data for 10 components \" + str(r2))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only one component gave very low R^2 values ​​on both the training and validation data. On the other hand, for R^2, the validation data do not change much from 3 to 10 components. We choose her 5 components between 3 and 10 components to ensure we eliminate overfitting. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Submission</b>\n",
    "First, predict the SalePrice of the homes in the test dataset. Then send the predictions to the working directory /haggle/working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test data so that it only has 7 components\n",
    "pca_7_test_img = pca_7.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five predictions for test dataset: \n",
      "[125152.29591648 158436.28549833 186369.0416353  181869.61110209\n",
      " 168184.60899383]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict prices of houses in the test dataset\n",
    "pred_test_7 = regr_7.predict(pca_7_test_img)\n",
    "print(\"First five predictions for test dataset: \")\n",
    "print(pred_test[:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>125152.295916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>158436.285498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>186369.041635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>181869.611102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>168184.608994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1466</td>\n",
       "      <td>168392.627254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1467</td>\n",
       "      <td>164611.734966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1468</td>\n",
       "      <td>153729.075397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1469</td>\n",
       "      <td>180267.001026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1470</td>\n",
       "      <td>126091.964269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  125152.295916\n",
       "1  1462  158436.285498\n",
       "2  1463  186369.041635\n",
       "3  1464  181869.611102\n",
       "4  1465  168184.608994\n",
       "5  1466  168392.627254\n",
       "6  1467  164611.734966\n",
       "7  1468  153729.075397\n",
       "8  1469  180267.001026\n",
       "9  1470  126091.964269"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['SalePrice'] = pred_test_7\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
